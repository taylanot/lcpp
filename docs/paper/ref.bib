@misc{yan2025,
      title={LCDB 1.1: A Database Illustrating Learning Curves Are More Ill-Behaved Than Previously Thought}, 
      author={Cheng Yan and Felix Mohr and Tom Viering},
      year={2025},
      eprint={2505.15657},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2505.15657}, 
}

@article{arma2016,
  title = {Armadillo: A Template-Based {{C}}++ Library for Linear Algebra},
  shorttitle = {Armadillo},
  author = {Sanderson, Conrad and Curtin, Ryan},
  year = {2016},
  month = jun,
  journal = {The Journal of Open Source Software},
  volume = {1},
  number = {2},
  pages = {26},
  issn = {2475-9066},
  doi = {10.21105/joss.00026},
  urldate = {2024-02-23},
}


@article{ensmallen2018,
  title = {Ensmallen: A Flexible {{C}}++ Library for Efficient Function Optimization},
  shorttitle = {Ensmallen},
  author = {Bhardwaj, Shikhar and Curtin, Ryan R. and Edel, Marcus and Mentekidis, Yannis and Sanderson, Conrad},
  year = {2018},
  month = dec,
  eprint = {1810.09361},
  primaryclass = {cs, math},
  doi = {10.5281/zenodo.2008650},
  urldate = {2024-02-21},
  archiveprefix = {arXiv},
  keywords = {65K10 68N99 68W99 90C53,Computer Science - Machine Learning,Computer Science - Mathematical Software,G.1.6 G.4,Mathematics - Optimization and Control},
}

@article{mlpack2023,
  title = {Mlpack 4: A Fast, Header-Only {{C}}++ Machine Learning Library},
  shorttitle = {Mlpack 4},
  author = {Curtin, Ryan R. and Edel, Marcus and Shrit, Omar and Agrawal, Shubham and Basak, Suryoday and Balamuta, James J. and Birmingham, Ryan and Dutt, Kartik and Eddelbuettel, Dirk and Garg, Rishabh and Jaiswal, Shikhar and Kaushik, Aakash and Kim, Sangyeon and Mukherjee, Anjishnu and Sai, Nanubala Gnana and Sharma, Nippun and Parihar, Yashwant Singh and Swain, Roshan and Sanderson, Conrad},
  year = {2023},
  month = feb,
  journal = {Journal of Open Source Software},
  volume = {8},
  number = {82},
  eprint = {2302.00820},
  primaryclass = {cs},
  pages = {5026},
  issn = {2475-9066},
  doi = {10.21105/joss.05026},
  urldate = {2024-02-23},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Mathematical Software},
}

@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@book{mitchell,
  title = {Machine Learning},
  author = {Mitchell, Tom M.},
  year = {2013},
  series = {{{McGraw-Hill}} Series in {{Computer Science}}},
  edition = {Nachdr.},
  publisher = {McGraw-Hill},
  address = {New York},
  isbn = {978-0-07-042807-2 978-0-07-115467-3},
  langid = {english},
}

@misc{viering2022,
      title={The Shape of Learning Curves: a Review}, 
      author={Tom Viering and Marco Loog},
      year={2022},
      eprint={2103.10948},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.10948}, 
}

@inproceedings{mohr2023,
  title = {{{LCDB}} 1.0: {{An}} Extensive Learning Curves Database for Classification Tasks},
  booktitle = {Machine Learning and Knowledge Discovery in Databases},
  author = {Mohr, Felix and Viering, Tom J. and Loog, Marco and {\noopsort{rijn}}{van Rijn}, Jan N.},
  editor = {Amini, Massih-Reza and Canu, St{\'e}phane and Fischer, Asja and Guns, Tias and Kralj Novak, Petra and Tsoumakas, Grigorios},
  doi = {10.1007/978-3-031-26419-1_1},
  year = {2023},
  pages = {3--19},
  publisher = {Springer Nature Switzerland},
  isbn = {978-3-031-26419-1}
}


@article{openml,
author = {Vanschoren, Joaquin and van Rijn, Jan N. and Bischl, Bernd and Torgo, Luis},
title = {OpenML: Networked Science in Machine Learning},
journal = {SIGKDD Explorations},
volume = {15},
number = {2},
year = {2013},
pages = {49--60},
url = {http://doi.acm.org/10.1145/2641190.2641198},
doi = {10.1145/2641190.2641198},
publisher = {ACM},
address = {New York, NY, USA},
}

@article{turan2025,
  title = {Learning {{Learning Curves}}},
  author = {Turan, O. Taylan and Tax, David M. J. and Viering, Tom J. and Loog, Marco},
  year = {2025},
  month = jan,
  journal = {Pattern Analysis and Applications},
  volume = {28},
  number = {1},
  pages = {15},
  issn = {1433-755X},
  doi = {10.1007/s10044-024-01394-6},
}


@article{turan2026,
title = {Generalization Performance Distributions Along Learning Curves},
journal = {Pattern Recognition Letters},
year = {2026},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2026.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167865526000012},
author = {O. Taylan Turan and Marco Loog and David M J Tax},
keywords = {learning curve, generalization performance, model selection, hyper-parameter tuning, quantiles},
abstract = {Learning curves show the expected performance with respect to training set size. This is often used to evaluate and compare models, tune hyper-parameters and determine how much data is needed for a specific performance. However, the distributional properties of performance are frequently overlooked on learning curves. Generally, only an average with standard error or standard deviation is used. In this paper, we analyze the distributions of generalization performance on the learning curves. We compile a high-fidelity learning curve database, both with respect to training set size and repetitions of the sampling for a fixed training set size. Our investigation reveals that generalization performance rarely follows a Gaussian distribution for classical classifiers, regardless of dataset balance, loss function, sampling method, or hyper-parameter tuning along learning curves. Furthermore, we show that the choice of statistical summary, mean versus measures like quantiles affect the top model rankings. Our findings highlight the importance of considering different statistical measures and use of non-parametric approaches when evaluating and selecting machine learning models with learning curves.}
}
